llm:
  provider: ${LLM_PROVIDER:-openai}
  model: ${LLM_MODEL:-gpt-4o}
  base_url: ${LLM_URL:-https://api.openai.com/v1/chat/completions}
  # Use environment variable to provide API key at runtime
  api_key: ${LLM_API_KEY:-}
  timeout: 30
  max_tokens: 4000
  temperature: 0.1
scanner:
  http_timeout: 30
  scan_timeout: 60
  detailed: false
  format: table
  parallel: true
  max_retries: 3
  retry_delay_ms: 1000
  llm_batch_size: 10
  enable_yara: true
security:
  enabled: true
  min_severity: low
  checks:
    tool_poisoning: true
    secrets_leakage: true
    sql_injection: true
    command_injection: true
    path_traversal: true
    auth_bypass: true
    prompt_injection: true
    pii_leakage: true
    jailbreak: true
logging:
  level: warn
  colored: true
  timestamps: true
performance:
  tracking: true
  slow_threshold_ms: 5000
# Tool storage directory for change detection (automatically created)
# tool_storage: "./tool_storage"
